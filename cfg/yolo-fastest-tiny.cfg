[net]
# Testing
;batch=1
;subdivisions=1
# Training
batch=64
subdivisions=8
# 416
width=320
height=320
channels=1
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 502000
policy=steps
steps=400000,450000
scales=.1,.1

[convolutional]
filters=8
size=3
pad=1
stride=2
batch_normalize=1
activation=leaky


[convolutional]
filters=8
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
groups=8
filters=8
size=3
stride=1
pad=1
batch_normalize=1
activation=leaky

[convolutional]
filters=4
size=1
stride=1
pad=0
batch_normalize=1
activation=linear

;[convolutional]
;filters=32
;size=1
;stride=1
;pad=0
;batch_normalize=1
;activation=leaky

[convolutional]
filters=32
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
groups=32
filters=32
size=3
stride=2
pad=1
batch_normalize=1
activation=leaky

[convolutional]
filters=8
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


[convolutional]
filters=48
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
groups=48
filters=48
size=3
pad=1
stride=1
batch_normalize=1
activation=leaky

[convolutional]
filters=8
size=1
stride=1
pad=0
batch_normalize=1
activation=linear

[dropout]
probability=.15

[shortcut]
from=-5
activation=linear

[convolutional]
filters=48
size=1
stride=2
pad=0
batch_normalize=1
activation=leaky

[convolutional]
groups=48
filters=48
size=3
pad=1
stride=2
batch_normalize=1
activation=leaky

[convolutional]
filters=16
size=1
stride=1
pad=0
batch_normalize=1
activation=linear

[convolutional]
filters=96
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
groups=96
filters=96
size=3
pad=1
stride=1
batch_normalize=1
activation=leaky

[convolutional]
filters=16
size=1
stride=1
pad=0
batch_normalize=1
activation=linear

[dropout]
probability=.15

[shortcut]
from=-5
activation=linear

[convolutional]
filters=96
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
groups=96
filters=96
size=3
pad=1
stride=2
batch_normalize=1
activation=leaky

[convolutional]
filters=16
size=1
stride=1
pad=0
batch_normalize=1
activation=linear

[convolutional]
filters=136
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
groups=136
filters=136
size=3
pad=1
stride=1
batch_normalize=1
activation=leaky

[convolutional]
filters=24
size=1
stride=1
pad=0
batch_normalize=1
activation=linear

[dropout]
probability=.15

[shortcut]
from=-5
activation=linear

[upsample]
stride = 2

[route]
layers=-1,14

[convolutional]
filters=224
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
groups=224
filters=224
size=5
stride=2
pad=1
batch_normalize=1
activation=leaky

[convolutional]
filters=96
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=128
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
groups=128
filters=128
size=5
stride=1
pad=1
batch_normalize=1
activation=leaky

[convolutional]
filters=128
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=125
size=1
stride=1
pad=1
activation=linear

[yolo]
mask = 0, 1, 2, 3, 4
anchors = 26, 48,  67, 84,  72,175, 189,126, 137,236, 265,259
classes=20
num=5
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=0
scale_x_y = 1.0
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6